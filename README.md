# ğŸ¦ Project: Global Market Index Analytics

## ğŸ“˜ Context
You are a **Data Engineer** at **GlobeQuant**, a financial analytics firm.  
The goal of this project is to build an **end-to-end data platform** that collects, transforms, analyzes, and forecasts **global stock index trends** to generate business intelligence and support investment decisions.

The system leverages the Kaggle dataset [Stock Exchange Data](https://www.kaggle.com/datasets/mattiuzc/stock-exchange-data), which includes global daily index data such as *open, high, low, close,* and *volume*.

---

## ğŸ“Š Objectives
- Ingest global index time series into a structured database.  
- Clean, normalize, and model index behavior across markets.  
- Provide analytics and dashboards to explore:
  - Cross-market trends  
  - Volatility and returns  
  - Forecasts and future insights  
- Enable filtering by region, index type, and time window.

---

## âš™ï¸ Technical Stack

| Layer | Tools / Frameworks | Description |
|-------|--------------------|--------------|
| **Data Ingestion** | Python (MySQL Connector) | Load raw CSV data into MySQL staging tables |
| **Data Warehouse / Analytics Store** | MySQL | Store transformed and analytical data |
| **Transformation & Modeling** | dbt (staging, intermediate, final models) | Data cleaning, metric computation, aggregation |
| **Forecasting** | Python (Prophet) | Predict index prices and volatility |
| **Orchestration** | Apache Airflow | Schedule and automate ingestion â†’ transform â†’ forecasting â†’ dashboard |
| **Visualization** | Plotly Dash | Interactive dashboard for analysis |
| **Documentation** | Markdown / PDF | System design and pipeline explanation |

---

## ğŸ§± Project Structure

```
global-market-index-analytics/
â”‚
â”œâ”€â”€ sql/              
â”‚   â”œâ”€â”€ create_tables.sql       â†’ SQL script to create raw tables.
â”‚   â””â”€â”€ load_data.py            â†’ Python ETL script to load CSV data into MySQL.
â”‚
â”œâ”€â”€ dbt/              
â”‚   â”œâ”€â”€ models/ 
â”‚   â”‚   â”œâ”€â”€ staging/            â†’ Clean and standardize raw index data (e.g. stg_global_index.sql)
â”‚   â”‚   â”œâ”€â”€ intermediate/       â†’ Compute daily returns, log returns, rolling volatility (int_market_metrics.sql)
â”‚   â”‚   â””â”€â”€ final/              â†’ Aggregate metrics by market and time (fct_market_summary.sql)
â”‚   â”œâ”€â”€ logs/                   â†’ dbt run logs and manifest files
â”‚   â”œâ”€â”€ dbt_packages/           â†’ Dependencies for dbt models
â”‚   â””â”€â”€ dbt_project.yml         â†’ dbt configuration file
â”‚
â”œâ”€â”€ forecasting/      
â”‚   â””â”€â”€ model_forecast.py      â†’ ML forecasting model for future index prices.
â”‚
â”œâ”€â”€ airflow/          
â”‚   â””â”€â”€ global-market-dag.py   â†’ Airflow DAG orchestrating ETL, dbt, and forecasting jobs.
â”‚
â”œâ”€â”€ dash/             
â”‚   â””â”€â”€ app.py                 â†’ Plotly Dash web app visualizing analytics and forecasts.
â”‚
â”œâ”€â”€ docs/             
â”‚   â”œâ”€â”€ architecture_diagram.png â†’ Data architecture and pipeline flow.
â”‚   â””â”€â”€ Project_Documentation.md â†’ Technical documentation.
â”‚
â””â”€â”€ README.md                  â†’ Project overview and run instructions.
```

---

## ğŸ§© dbt Model Lineage

```
stg_global_index.sql
      â†“
int_market_metrics.sql
      â†“
fct_market_summary.sql
```

**Explanation:**
1. **Staging Layer (`stg_global_index.sql`)**  
   - Loads and cleans raw CSV data.  
   - Converts data types and removes nulls.

2. **Intermediate Layer (`int_market_metrics.sql`)**  
   - Calculates **daily returns**, **log returns**, and **rolling volatility**.  
   - Prepares data for analytical use.

3. **Final Layer (`fct_market_summary.sql`)**  
   - Aggregates metrics across indices and computes average volatility & return.  
   - Provides data for dashboards and forecasting.

---

## ğŸ“ˆ Data Flow Overview

```
Raw CSV Data (Kaggle)
        â†“
MySQL (Staging Tables)
        â†“
dbt Transformations (Staging â†’ Intermediate â†’ Final)
        â†“
Forecasting Engine (model_forecast.py)
        â†“
Dash Dashboard (app.py)
```

---

## ğŸ•¹ï¸ Airflow Orchestration

**DAG:** `global-market-dag.py`  
**Tasks:**
1. `ingest_data` â†’ Run `load_data.py`  
2. `run_dbt` â†’ Execute dbt transformations  
3. `dbt_test` â†’ Test dbt
4. `forecast_model` â†’ Generate forecasts  
5. `update_dashboard` â†’ Refresh Dash data layer

---

## ğŸ“‰ Forecasting Logic
- The script `model_forecast.py` trains a time-series model on historical **close prices**.
- It outputs:
  - **Next 7-day price forecasts**
  - **Confidence intervals**
  - **Forecast accuracy metrics (MAE, RMSE)**

---

## ğŸ“Š Dashboard Features (dash/app.py)
- View **index time series** for global markets.  
- Compare **regions (US, EU, Asia)** by volatility and return.  
- Display **forecasted vs actual** trends.  
- Highlight **high-risk periods** using alerts and color-coded charts.

---

## ğŸ§  Architecture Diagram
*(Located in `docs/architecture_diagram.png`)*  

**Components:**
- **Source:** CSV datasets (Kaggle)  
- **Storage:** MySQL (Raw/Staging)  
- **Transformation:** dbt (staging â†’ intermediate â†’ final)  
- **Forecasting:** Python ML script  
- **Orchestration:** Airflow  
- **Visualization:** Dash  

---

## ğŸ§° Setup & Execution

### 1. Environment Setup
```bash
pip install -r requirements.txt
```

### 2. Database Setup
```bash
mysql -u admin -p < sql/create_tables.sql
python sql/load_data.py
```

### 3. Run dbt Models
```bash
cd dbt
source ~/venv/bin/activate
dbt debug
dbt run
```

### 4. Run Forecasting
```bash
python forecasting/model_forecast.py
```

### 5. Launch Dashboard
```bash
python dash/app.py
```

### 6. Airflow DAG
```bash
airflow standalone
```

---

## ğŸ—‚ï¸ Deliverables
- âœ… Source Code Repository (structured as above)
- âœ… Technical Documentation (this file)
- âœ… Data Flow & Architecture Diagram (`docs/architecture_diagram.png`)
- âœ… dbt Model Lineage Graph
- âœ… Forecasting Script & Dashboard
